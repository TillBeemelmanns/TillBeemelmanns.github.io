I"¤<p><a href="https://www.cityscapes-dataset.com/">Cityscapes</a> is a great dataset for <strong>semantic image segmentation</strong> which is widely used in academia in the context of automated driving. This dataset provides pixel-precise class annotations on the full image from a vehicleâ€™s perspective. However, sometimes you are only interested in the 2D bounding box of specific objects such as <code class="language-plaintext highlighter-rouge">cars</code> or <code class="language-plaintext highlighter-rouge">pedestrians</code> in order to perform 2D object detection on the image.</p>

<p>The annotations in Cityscapes also considers segmentation instances. That means a single object is defined by the segmentation mask and an unique instance ID. We can use that information to transform such an instance and extract the extend of it, in short: the <strong>2D bounding box</strong>. Furthermore, we can also determine the area that is covered by that instance, which is called the <strong>mask</strong>. Together, we would obtain labels for <strong>object segmentation</strong> as shown in the head image above.</p>

<h3 id="cityscapes-to-coco-conversion-tool">Cityscapes to Coco Conversion Tool</h3>
<p>To convert the Cityscapes dataset into a Coco format dataset you may use my <a href="https://github.com/TillBeemelmanns/cityscapes-to-coco-conversion">Cityscapes Coco conversion tool</a>. You can use it as described in the following:</p>

<h4 id="usage">Usage</h4>
<p>Clone the repository</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/TillBeemelmanns/cityscapes-to-coco-conversion
</code></pre></div></div>
<p>and install the requirements:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install -r requirements.txt 
</code></pre></div></div>
<p>You may setup a <a href="https://docs.python.org/3/library/venv.html"><em>virtual environment</em></a> to do so.</p>

<h5 id="download-the-cityscapes-dataset">Download the Cityscapes dataset</h5>
<p>Download the <a href="https://www.cityscapes-dataset.com/">Cityscapes dataset</a>. Download <code class="language-plaintext highlighter-rouge">gtFine_trainvaltest.zip</code> and also <code class="language-plaintext highlighter-rouge">leftImg8bit_trainvaltest.zip</code>. You may have to register in order to download them. Setup the following file structure.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data/
â””â”€â”€ cityscapes
    â”œâ”€â”€ annotations
    â”œâ”€â”€ gtFine
    â”‚   â”œâ”€â”€ test
    â”‚   â”œâ”€â”€ train
    â”‚   â””â”€â”€ val
    â””â”€â”€ leftImg8bit
        â”œâ”€â”€ test
        â”œâ”€â”€ train
        â””â”€â”€ val
main.py
inspect_coco.py
README.md
requirements.txt
</code></pre></div></div>

<p>Now you can start the conversion script by calling</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py <span class="nt">--dataset</span> cityscapes <span class="nt">--datadir</span><span class="o">=</span><span class="s2">"data/cityscapes"</span> <span class="nt">--outdir</span><span class="o">=</span><span class="s2">"data/cityscapes/annotations"</span>
</code></pre></div></div>

<p>The script will create the files</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">instancesonly_filtered_gtFine_train.json</code></li>
  <li><code class="language-plaintext highlighter-rouge">instancesonly_filtered_gtFine_val.json</code></li>
</ul>

<p>in the directory <code class="language-plaintext highlighter-rouge">annotations</code> for the <code class="language-plaintext highlighter-rouge">train</code> and <code class="language-plaintext highlighter-rouge">val</code> split which contain the Coco annotations.</p>

<h4 id="filter-certain-classes">Filter certain classes</h4>
<p>The Cityscapes dataset contains about 30 different classes. Not all of them may be relevant for you. The variable <code class="language-plaintext highlighter-rouge">category_instancesonly</code> defines which classes should be considered in the conversion process.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">category_instancesonly</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'person'</span><span class="p">,</span>
    <span class="s">'rider'</span><span class="p">,</span>
    <span class="s">'car'</span><span class="p">,</span>
    <span class="s">'truck'</span><span class="p">,</span>
    <span class="s">'bus'</span><span class="p">,</span>
    <span class="s">'train'</span><span class="p">,</span>
    <span class="s">'motorcycle'</span><span class="p">,</span>
    <span class="s">'bicycle'</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div></div>

<p>On these mentioned classes will be converted into a Coco annotation.</p>

<p>Sometimes the segmentation annotations are so small that no reasonable big enough object could be created. In this case the, the object will be skipped.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Warning: invalid contours.
</code></pre></div></div>

<h3 id="output">Output</h3>
<p>You can visualize the final <strong>object segmentation</strong> annotations with the inspection script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python inspect_coco.py --coco_dir data/cityscapes
</code></pre></div></div>
<p>And you would obtain some of the following pictures:</p>

<p><img src="/assets/images/convert-cityscapes-to-coco/plot1.png" alt="" />
<img src="/assets/images/convert-cityscapes-to-coco/plot2.png" alt="" /></p>

<h4 id="wrap-up">Wrap-up</h4>
<ul>
  <li>You converted a <strong>image segmentation</strong> dataset into a <strong>object segmentation</strong> dataset</li>
  <li>You can now use the new dataset with <a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN</a>, <a href="https://github.com/facebookresearch/detr">DETR</a> or <a href="https://github.com/facebookresearch/detectron2">Detectron2</a> network architectures</li>
</ul>
:ET